{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0tt00t/ECS170-Project/blob/main/Fashion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writeup\n",
        "\n",
        "For the writeup, please include the following information:\n",
        "\n",
        "\n",
        "*   Convolutional neural network: \n",
        "-  - An input layer, hidden layers, and an output layer make up a convolutional neural network. Any middle layers in a feed-forward neural network are referred to as hidden layers since the activation function and final convolution hide their inputs and outputs. The convolution procedure develops a feature map as the convolution kernel moves across the input matrix for the layer.\n",
        "\n",
        "*   Discuss how you tuned your network and why you think it's performance is reasonable for this task\n",
        "\n",
        "\n",
        "- - Initially, I tried to use three fully connected layer, but the percising rate got stucked on about 85%. Then, I tried to add another layer and adjust the input layer match the matrix(which is the 9216). I choose two convolutional layer with kernel size 2. This is because comparing to the RGB pictures, the black and white pictures need more percise examination. What's more, for the learning rate, we found out that the learning rate 0.015 will be most productive. Finally, we set epouch to 20. Even though sometimes the model shows overstudy, but most of the time will get over 90% accuricy. Combinating all the variables we tuned, we got our final model.\n",
        "\n",
        "*   Discuss wether or not you feel that this classifier is appropriate for the given task (check PA3 description)\n",
        "\n",
        "- - When we train our model, the accuracy of our model is 80% at our first epoch. Since we set the number of epoch to 20, the accuracy of our model keeps rising as we get to 20 epochs. In the end, the accuracy of our model can go up to 9029/10000 which is 90%. In this case, if we implement our model to the shipping facility. There is only one wrong selection in 10 clothes. As we get the wrong result, we can learn from the wrong result and keeps upgrade the accuracy of our model."
      ],
      "metadata": {
        "id": "qxOhrr4P1jWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "wJImnLRvS10E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 Imports"
      ],
      "metadata": {
        "id": "9Oj-THYrHY-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJF_htAsHP18"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Set Hyperparameters"
      ],
      "metadata": {
        "id": "o7QPmU2THeE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can modify these values\n",
        "\n",
        "n_epochs = 20\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.015\n",
        "momentum = 0.5\n",
        "log_interval = 100"
      ],
      "metadata": {
        "id": "Q2jvrRp6Hdhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Data"
      ],
      "metadata": {
        "id": "5BF4XieJH6r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "  root = './data/FashionMNIST',\n",
        "  train = True,\n",
        "  download = True,\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor()                                 \n",
        "  ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                     batch_size = batch_size_train,\n",
        "                                     shuffle=True)\n",
        "\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "  root = './data/FashionMNIST',\n",
        "  train = False,\n",
        "  download = True,\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor()                                 \n",
        "  ]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                     batch_size = batch_size_train,\n",
        "                                     shuffle=True)"
      ],
      "metadata": {
        "id": "9ksSnoOcH_2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "leynP5FNILE6",
        "outputId": "85508af6-c6f1-4a8e-ba63-539927702676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CHANNELS = example_data.shape[1]\n",
        "\n",
        "OUTPUT_CLASSES = 10\n",
        "example_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SVbsV3JJOyN",
        "outputId": "98d1fe4f-3b53-4c15-ab82-c71890a894b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define Model"
      ],
      "metadata": {
        "id": "jd448qcTI08A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input channels, output channels, kernel size, stride\n",
        "        self.conv1 = nn.Conv2d(INPUT_CHANNELS, 128, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(128, 256, 2, 1)\n",
        "        self.maxPooling = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(9216, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 64)\n",
        "        self.fc4 = nn.Linear(64, OUTPUT_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxPooling(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxPooling(x)\n",
        "        linearize = nn.Flatten()\n",
        "        x = linearize(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "FPJ3fN3IIubV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net().to(device)\n",
        "net"
      ],
      "metadata": {
        "id": "cMoEjiakOJ0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0891a948-bc61-4df2-9a6f-7657f8c5252d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 128, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (conv2): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (maxPooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=9216, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train Model"
      ],
      "metadata": {
        "id": "HtfpbeNoKA-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "U3PqYa_JKW5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "SdQxhR9LKAWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(net, train_loader, optimizer, epoch)\n",
        "  test(net, test_loader)"
      ],
      "metadata": {
        "id": "cO6SfXSkKbIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2609b80-9640-4a43-a9d1-85247c7163a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.326385\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.823768\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.672040\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.724265\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.643394\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.407877\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.627572\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.447640\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.394048\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.479826\n",
            "\n",
            "Test set: Average loss: 0.5574, Accuracy: 8015/10000 (80%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.409819\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.384002\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.413823\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.506972\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.413249\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.438667\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.423068\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.400868\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.352968\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.331662\n",
            "\n",
            "Test set: Average loss: 0.4687, Accuracy: 8288/10000 (83%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.560135\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.425735\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.494065\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.349954\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.375370\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.294463\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.371153\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.294620\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.329604\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.390135\n",
            "\n",
            "Test set: Average loss: 0.4751, Accuracy: 8280/10000 (83%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.220134\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.502877\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.486879\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.707189\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.283023\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.314904\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.381648\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.333054\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.378657\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.524325\n",
            "\n",
            "Test set: Average loss: 0.3609, Accuracy: 8703/10000 (87%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.332560\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.407906\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.279813\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.375131\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.316934\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.519514\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.434984\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.305526\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.422928\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.378523\n",
            "\n",
            "Test set: Average loss: 0.3861, Accuracy: 8549/10000 (85%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.386897\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.293943\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.282985\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.312933\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.316387\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.258651\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.352750\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.279878\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.208685\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.296612\n",
            "\n",
            "Test set: Average loss: 0.3446, Accuracy: 8786/10000 (88%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.270001\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.252445\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.329367\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.120836\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.221105\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.400385\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.207344\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.212653\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.319938\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.309817\n",
            "\n",
            "Test set: Average loss: 0.3206, Accuracy: 8863/10000 (89%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.242253\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.112408\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.191078\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.263477\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.284264\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.266676\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.352372\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.475275\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.282916\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.277652\n",
            "\n",
            "Test set: Average loss: 0.3137, Accuracy: 8872/10000 (89%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.234781\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.276185\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.312224\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.229307\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.262711\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.350197\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.216816\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.401015\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.458600\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.361911\n",
            "\n",
            "Test set: Average loss: 0.3152, Accuracy: 8833/10000 (88%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.157752\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.235244\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.345153\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.299757\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.341266\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.158643\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.419611\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.218148\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.239254\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.279501\n",
            "\n",
            "Test set: Average loss: 0.3250, Accuracy: 8827/10000 (88%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.199494\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.438043\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.263094\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.183198\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.334926\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.411947\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.385168\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.368902\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.214847\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.248486\n",
            "\n",
            "Test set: Average loss: 0.3131, Accuracy: 8871/10000 (89%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.451785\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.279613\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.144222\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.117984\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.309114\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.265626\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.160550\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.271044\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.262976\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.146058\n",
            "\n",
            "Test set: Average loss: 0.2861, Accuracy: 8980/10000 (90%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.325884\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.465391\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.386875\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.237617\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.395970\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.240477\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.284131\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.366567\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.128638\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.281156\n",
            "\n",
            "Test set: Average loss: 0.2979, Accuracy: 8924/10000 (89%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.266671\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.219386\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.232871\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.130136\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.158184\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.267908\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.363843\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.202962\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.256717\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.267620\n",
            "\n",
            "Test set: Average loss: 0.3210, Accuracy: 8862/10000 (89%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.237684\n",
            "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.145545\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.343741\n",
            "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.212678\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.189952\n",
            "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.127493\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.102181\n",
            "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.121007\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.238265\n",
            "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.230862\n",
            "\n",
            "Test set: Average loss: 0.2844, Accuracy: 9004/10000 (90%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.196004\n",
            "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.275408\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.263412\n",
            "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.138870\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.103129\n",
            "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.370410\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.209378\n",
            "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.243428\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.150625\n",
            "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.089806\n",
            "\n",
            "Test set: Average loss: 0.2872, Accuracy: 8971/10000 (90%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.227907\n",
            "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.173390\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.152976\n",
            "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.125215\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.144296\n",
            "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.153722\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.271754\n",
            "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.169100\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.159665\n",
            "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.635388\n",
            "\n",
            "Test set: Average loss: 0.2987, Accuracy: 8923/10000 (89%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.211356\n",
            "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.306306\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.179918\n",
            "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.115768\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.325051\n",
            "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.125391\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.124628\n",
            "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.283157\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.171294\n",
            "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.194447\n",
            "\n",
            "Test set: Average loss: 0.2994, Accuracy: 8959/10000 (90%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.130886\n",
            "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.246169\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.182606\n",
            "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.191334\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.477949\n",
            "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.184079\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.099410\n",
            "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.146786\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.236646\n",
            "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.178502\n",
            "\n",
            "Test set: Average loss: 0.3016, Accuracy: 8921/10000 (89%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.429443\n",
            "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.260299\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.148679\n",
            "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.208292\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.176655\n",
            "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.078610\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.133292\n",
            "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.104636\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.171853\n",
            "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.163974\n",
            "\n",
            "Test set: Average loss: 0.2904, Accuracy: 9029/10000 (90%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow"
      ],
      "metadata": {
        "id": "4XcY-TlhGxru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Imports"
      ],
      "metadata": {
        "id": "KyU1ThEPG0Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "0F1QY_IOG2e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Set Hyperparameters"
      ],
      "metadata": {
        "id": "qJe1xk4QHEvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune these\n",
        "\n",
        "n_epochs = 3\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "tsXzcHqDHTku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import Data"
      ],
      "metadata": {
        "id": "n13sUlF_HJ1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'fashion_mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(batch_size_train)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size_test)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "W4uIM9TaHWUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define Model"
      ],
      "metadata": {
        "id": "DgEqnLBsR3W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  ## Your architecture goes here\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ],
      "metadata": {
        "id": "v4wX6lQOHjeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train Model"
      ],
      "metadata": {
        "id": "f5VZLjUSHNl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=n_epochs,\n",
        "    validation_data=ds_test,\n",
        ")"
      ],
      "metadata": {
        "id": "GQp_7VQtHwXi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f13966f6-1112-4bef-ef3f-8f9906f52e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-221-deb9191fa411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1233, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 346, in wrapper\n      runner = Runner(result, future, yielded)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1080, in __init__\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-221-deb9191fa411>\", line 4, in <module>\n      validation_data=ds_test,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 729, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 4086, in sparse_categorical_accuracy\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_142080]"
          ]
        }
      ]
    }
  ]
}